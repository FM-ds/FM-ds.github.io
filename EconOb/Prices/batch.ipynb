{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "from selenium.webdriver import Keys, ActionChains\n",
    "from selenium.webdriver.common.actions.action_builder import ActionBuilder\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import openai\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching Tesco Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products(driver):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        driver: webdriver\n",
    "    Returns:\n",
    "        list of products\n",
    "    Gets all products from the tesco page and returns them as a list of dictionaries\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    products = []\n",
    "    a_s = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    for a in a_s:\n",
    "        # check if a has a href attribute\n",
    "        if(a.get_attribute('href') != None and'/products/' in a.get_attribute('href')):\n",
    "            product = {}\n",
    "            count += 1\n",
    "            #print(f\"{count}:{a.get_attribute('href')}\")\n",
    "            try:\n",
    "                span_child = a.find_element(By.TAG_NAME, \"span\")\n",
    "                product = {'name': span_child.text, 'link': a.get_attribute('href'), 'source_page': driver.getCurrentUrl(), 'scrape_time': time.time() }\n",
    "                gp = a.find_element(By.XPATH, '..')\n",
    "                gp = gp.find_element(By.XPATH, '..')\n",
    "                p_elements = gp.find_elements(By.TAG_NAME, \"p\")\n",
    "                prices = []\n",
    "                for p in p_elements:\n",
    "                    if 'Â£' in p.text:\n",
    "                        prices.append(p.text)\n",
    "                product['prices'] = prices\n",
    "                products.append(product)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return products\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    {\"name\": \"fresh-food\", \"page_count\":77},\n",
    "    {\"name\": \"bakery\", \"page_count\": 15}, \n",
    "    {\"name\": \"frozen-food\", \"page_count\": 22}, \n",
    "    {\"name\": \"treats-and-snacks\", \"page_count\": 39},\n",
    "    {\"name\": \"food-cupboard\", \"page_count\": 124},\n",
    "    {\"name\": \"drinks\", \"page_count\": 66},\n",
    "    {\"name\": \"household\", \"page_count\": 26},\n",
    "    {\"name\": \"home-ents\", \"page_count\": 87},\n",
    "    {\"name\": \"health-and-beauty\", \"page_count\": 80},\n",
    "    {\"name\": \"baby-and-toddler\", \"page_count\": 19},\n",
    "    {\"name\": \"pets\", \"page_count\": 16}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
